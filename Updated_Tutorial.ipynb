{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tutorial based from the paper : \"An Evaluation of Naive Bayesian Anti-Spam Filtering\n",
    "\n",
    "This is a tutorial to replicate the process of the paper entitled: \"An Evaluation of Naive Bayesian Anti-Spam Filtering. The objective of the paper is to filter spam emails using a Naive Bayes Techinique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Data\n",
    "\n",
    "The dataset provided to us has 4 directories [bare, lemm, lemm_stop, stop] with subdirectories of 10 parts. Where 9 were used as training set and 1 reserved for testing for every repetition. To reduce random variation, a ten cross-validation was done yielding the ten subdirectories.\n",
    "\n",
    "We could first parse all subdirectories into a list like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# eg. passed directory = 'Emails\\\\bare'\n",
    "# reads its subdirectories and files into a list of lists\n",
    "def parse_subdirectories(directory):\n",
    "    for path, subdirs, files in os.walk(directory):\n",
    "        dir_dataset = []\n",
    "        for filename in files:\n",
    "            f = os.path.join(path,filename)\n",
    "            subdir_content = []\n",
    "            with open(f,'r') as file_content:\n",
    "                content = file_content.read()\n",
    "                subdir_content.append(content)\n",
    "        dir_dataset.append(subdir_content)\n",
    "    return dir_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split this data into 90% training set for Naive Bayes prediction and 10% data for accuracy testing. Let's call these variables: train_set and test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def spilt_dataset(dataset, n_split):\n",
    "    train_set = []\n",
    "    data_copy = list(dataset)\n",
    "    while len(train_set) < int(len(dataset)*n_split):\n",
    "        pointer = random.randrange(len(data_copy))\n",
    "        train_set.append(data_copy.pop(pointer))\n",
    "    return [train_set,data_copy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To form a list of features to finally use in predicting classification using the Naive Bayes theorem, a common feature selection method is done by computing the Mutual Information (MI) of term t and class c \n",
    "\n",
    "where, \n",
    "- t is defined to be a word attribute and;\n",
    "- classified either as c = spam or not spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regina : Perform Tokenization\n",
    "# Regina : Perform MI computation\n",
    "# Select attributes from the highest MI of all possible attributes from the training corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
