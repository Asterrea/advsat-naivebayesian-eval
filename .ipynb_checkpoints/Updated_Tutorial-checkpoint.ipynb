{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tutorial based from the paper : \"An Evaluation of Naive Bayesian Anti-Spam Filtering\n",
    "\n",
    "This is a tutorial to replicate the process of the paper entitled: \"An Evaluation of Naive Bayesian Anti-Spam Filtering. The objective of the paper is to filter spam emails using a Naive Bayes Techinique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Data\n",
    "\n",
    "The dataset provided to us has 4 directories [bare, lemm, lemm_stop, stop] with subdirectories of 10 parts. Where 9 were used as training set and 1 reserved for testing for every repetition. To reduce random variation, a ten cross-validation was done yielding the ten subdirectories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To form a list of features to finally use in predicting classification using the Naive Bayes theorem, a common feature selection method is done by computing the Mutual Information (MI) of term t and class c \n",
    "\n",
    "where, \n",
    "- <i>t</i> is defined to be a word attribute and;\n",
    "- classified either as <i>c</i> = spam or not spam. \n",
    "\n",
    "We are given a description <i>d âˆˆ X</i> of a document, where <i>X</i> is the document space; and a fixed set of classes <i>C = {spam, legitimate}</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our data to filter out spam, we need to find the features that will be used, the paper used the words found in the corpus as the features of the classifier. We created a whole tutorial on feature extraction alone, refer to another notebook named: <b><i>Jupyter Feature Extraction : Feature Extraction.ipynb</i></b>.\n",
    "\n",
    "It will generate a csv file that has:\n",
    "1. Term\n",
    "2. Number of legitimate emails that word occurred in\n",
    "3. Number of spam emails that word occurred in\n",
    "4. Mutual Information Count\n",
    "\n",
    "After reading the feature extraction tutorial, you already have the list of all the terms in each corpus with their corresponding Mutual Information score, the following function will extract n-terms with the highest <i>MI</i>. The you/system decide how many features will be used. \n",
    "\n",
    "The paper used 50 - 700 features, stepping by 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, check MI folder\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "numMI = [50,100,150,200,250,300,350,400,450,500,550,600,650,700]\n",
    "corpus = ['bare','lemm', 'lemm_stop', 'stop']\n",
    "\n",
    "for corp in corpus:\n",
    "    for num in numMI:\n",
    "        termMIList = pd.read_csv(\"Features/\"+corp+\"/\"+corp+\"termMI.csv\", index_col = 0)\n",
    "        terms = pd.DataFrame(termMIList['Term'].head(n=num).tolist()).to_csv(\"MI/\"+corp+\"/\"+str(num)+\"terms.txt\", header = None, index = None)\n",
    "print (\"Done, check MI folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the train and test set split by passing the extracted <i>.txt</i> file to the function below that automatically walks through the directory given to it and transfers the contents of the text file into a list called <i>dir_dataset</i>, where the function <i>parse_subdirectories</i> returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# eg. passed directory = 'Emails/bare'\n",
    "# reads its subdirectories and files into a list of lists\n",
    "def parse_subdirectories(directory):\n",
    "    for path, subdirs, files in os.walk(directory):\n",
    "        dir_dataset = []\n",
    "        for filename in files:\n",
    "            f = os.path.join(path,filename)\n",
    "            subdir_content = []\n",
    "            with open(f,'r') as file_content:\n",
    "                content = file_content.read()\n",
    "                subdir_content.append(content)\n",
    "        dir_dataset.append(subdir_content)\n",
    "    return dir_dataset\n",
    "\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split this list data into 90% training set and 10% data for accuracy testing of Naive Bayes prediction. Let's call these list variables: <i>train_set</i> and <i>test_set</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def split_dataset(dataset, n_split):\n",
    "    train_set = []\n",
    "    data_copy = list(dataset)\n",
    "    while len(train_set) < int(len(dataset)*n_split):\n",
    "        pointer = random.randrange(len(data_copy))\n",
    "        train_set.append(data_copy.pop(pointer))\n",
    "    return [train_set,data_copy]\n",
    "\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Email/Documents \n",
    "\n",
    "In order to classify the documents whether it is of category spam or legit. To do this, we ought to apply the formula of Bayes which needs the probability of the extracted terms/features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier we will be building will use \"supervised learning\". Now that we have the a list of features, its association with all messages using the term matrix, this will form the basis of the classifier.\n",
    "\n",
    "Once we have associated the various words with our two classifications (spam and legit), we can calculate the probability that a given word belongs to either spam or legit category. For instance, the probability that the word \"vintage\" appears in a spam message is much higher than the probability it appears in a legitimate email.\n",
    "\n",
    "For example, once we have trained our classifier using 200 documents, 100 are spam and 100 are legit. If word \"vintage\" appears in 25 spam documents, but only 5 legit documents. The probability, then, that the word \"vintage\" classifies as a spam document is calculated:\n",
    "\n",
    "$$P(\"vintage\" | spam) = (.25 * .5) / ((.25 * .5) + (.05 * .5)) = .83, or 83%.$$\n",
    "\n",
    "The \".25\" and \".05\" are the percentage of documents containing the word money that are spam and ham respectively. The \".5\" is the interesting number and is the percentage of documents that are spam or legit. Since we have classified 100 of each, the total number of documents is 200, and it is overall 50% likely that a document is spam.\n",
    "\n",
    "By combining the probabilities for all the words in a document, it is possible to get an overall view of the likelihood a document is either spam or legit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed in computing for the probability of classifiying it as a spam or not with the equation:\n",
    "\n",
    "$$\\frac{P(C=spam|\\vec{X} = \\vec{x})}{P(C=legitimate | \\vec{X} = \\vec{x})} > \\lambda$$\n",
    "\n",
    "The equation tells us that we need the vectors from the term matrix (counts) which indicates association between the features and documents in order to assess if it is a spam or not.\n",
    "\n",
    "Let's create function/s for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from decimal import *\n",
    "\n",
    "getcontext().prec = 256\n",
    "getcontext().rounding = ROUND_UP\n",
    "\n",
    "# A = P(X=x|C=c)\n",
    "# P(A|B), is equal to P(AB)/P(B).\n",
    "# P(A) = (Total number of times x occurred/total number of term occurrence in the corpus)\n",
    "# P(B) = (Total number of email c in the corpus /total number of documents in the corpus)\n",
    "#termProb = total number of times x occurred  in document\n",
    "\n",
    "\n",
    "def computeTermGivenClass(probClass, terms, totalTerms):\n",
    "    prob = Decimal(1.0)\n",
    "    for x in terms:\n",
    "        a = (Decimal(x)/Decimal(totalTerms))\n",
    "        prob = (Decimal(prob) * (Decimal(a)/Decimal(probClass)))\n",
    "    \n",
    "    return prob\n",
    "\n",
    "#B = P(X=x) = (Total number of times x occurred in the corpus)/(Total number of word occurrence in the corpus)\n",
    "#C = P(C=c) = (Total number of documents that are c in the corpus)/(Total number of documents in the corpus)\n",
    "          \n",
    "def computeProbability(isComputingSpam, totalDoc, spamTerms, legitTerms, totalTerms, totalLegitCount, totalSpamCount):\n",
    "      \n",
    "    probSpam = (totalSpamCount/totalDoc)\n",
    "    probLegit = (totalLegitCount/totalDoc)\n",
    "    \n",
    "    givenSpam =  (Decimal(probSpam) * computeTermGivenClass(probSpam, spamTerms, totalTerms))\n",
    "    givenLegit = (Decimal(probLegit) * computeTermGivenClass(probLegit, legitTerms, totalTerms))\n",
    "    \n",
    "    if isComputingSpam == True:\n",
    "        numerator =  givenSpam\n",
    "    else:\n",
    "        numerator =  givenLegit\n",
    "            \n",
    "    denominator = Decimal(givenSpam) + Decimal(givenLegit)\n",
    "    try:\n",
    "        probClass = Decimal(numerator/denominator)\n",
    "    except:\n",
    "        probClass = 0\n",
    "    return probClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def extractWords(filepath):\n",
    "    file = open(filepath, 'r')\n",
    "    # .lower() returns a version with all upper case characters replaced with lower case characters.\n",
    "    text = file.read().lower()\n",
    "    file.close()\n",
    "    # replaces anything that is not a lowercase letter, a space, or an apostrophe with a space:\n",
    "    text = re.sub('[^a-z]+', \" \", text)\n",
    "    words = list(text.split())\n",
    "    \n",
    "     # remove duplicate words in the list\n",
    "    words = list(set(words))\n",
    "    # removes words that are less than 4 letters/characters\n",
    "    words =  [i for i in words if len(i) >= 4] \n",
    "    return words;\n",
    "\n",
    "def findTermCounts(terms, docTerms):\n",
    "    return terms.loc[terms['Term'].isin(docTerms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyDocs(corp, terms, spamCount, legitCount, totalTerms,\n",
    "             fileList, threshold, numFeatures):\n",
    "    \n",
    "    totalDoc = corp.totalEmailCtr\n",
    "    totalLegitCount = corp.legitEmailCtr\n",
    "    totalSpamCount = corp.spamEmailCtr\n",
    "\n",
    "    predicted = []\n",
    "    for filepath in fileList:   \n",
    "\n",
    "        docTerms = extractWords(filepath)\n",
    "        rowTerms = findTermCounts(terms, docTerms)\n",
    "        PCSpam = Decimal(computeProbability(True, totalDoc, spamCount, legitCount, \n",
    "                                            totalTerms, totalLegitCount, totalSpamCount))\n",
    "        PCLegit = Decimal(computeProbability(False, totalDoc, spamCount, legitCount, \n",
    "                                            totalTerms, totalLegitCount, totalSpamCount))\n",
    "        \n",
    "        try:\n",
    "            ifSpam = PCSpam/PCLegit\n",
    "        except:\n",
    "            ifSpam = 0\n",
    "            \n",
    "        if  ifSpam > threshold:\n",
    "            predicted.append(0)\n",
    "        else:\n",
    "            predicted.append(1)\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a class for the the Corpus data, it will store the total number of emails in the corpus, \n",
    "# along with the total number of spam and legit emails\n",
    "class CorpusData: \n",
    "    corpusName = \"\"\n",
    "    totalEmailCtr = 0\n",
    "    spamEmailCtr = 0\n",
    "    legitEmailCtr = 0\n",
    "\n",
    "    def __init__(self, corpusName, totalEmailCtr, spamEmailCtr, legitEmailCtr):\n",
    "        self.corpusName = corpusName\n",
    "        self.totalEmailCtr = totalEmailCtr\n",
    "        self.spamEmailCtr = spamEmailCtr\n",
    "        self.legitEmailCtr = legitEmailCtr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combineFiles(corp):\n",
    "    #for each subdirectory in a corpus (folders - part 1 - 10)\n",
    "    fileList = []\n",
    "    rootdir = \"Emails/\"+corp\n",
    "    actualClass = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "    #for each file in a folder\n",
    "        for file in files:\n",
    "            filepath = subdir + \"/\" + file\n",
    "            fileList.append(filepath)\n",
    "            \n",
    "            if pattern.match(file): \n",
    "                    actualClass.append(1)\n",
    "            else:\n",
    "                    actualClass.append(0)\n",
    "    \n",
    "    return fileList, actualClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeResults(actual, predicted, corp, featureNum, thresh):\n",
    "    results = pd.DataFrame(\n",
    "        {'Actual': actual,\n",
    "         'Predicted' : predicted,\n",
    "        })\n",
    "\n",
    "    #save the Term MI to CSV (so we can access it later)\n",
    "    results.to_csv(\"Classified/\"+corp.corpusName +\"/\"+str(featureNum)+\"/\"+str(thresh)+\"_results.csv\")\n",
    "    print(\"File Saved: \", corp.corpusName , featureNum, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total emails, total spam emails, total legit emails\n",
    "bare = CorpusData(\"bare\", 2515, 304, 2211)\n",
    "lemm = CorpusData(\"lemm\", 2776, 452, 2324)\n",
    "lemm_stop = CorpusData(\"lemm_stop\", 2609, 281, 2409)\n",
    "stop = CorpusData(\"stop\", 2341, 481, 1860)\n",
    "\n",
    "\n",
    "numFeatures = [50,100,150,200,250,300,350,400,450,500,550,600,650,700]\n",
    "# 0.5 - 1, 0.9 - 9, 0.999 - 999\n",
    "threshold = [0.5, 0.9, 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(corp):\n",
    "    print (\"Classifying\", corp.corpusName)\n",
    "    #load the vocabulary/word/term list for the entire corpus from file\n",
    "    corpusTerms = pd.read_csv(\"Features/\"+corp.corpusName+\"/\"+corp.corpusName+\"termMI.csv\", index_col = 0)\n",
    "    totalLegitTerms = corpusTerms['LegitCount'].sum(axis=0)\n",
    "    totalSpamTerms = corpusTerms['SpamCount'].sum(axis=0)\n",
    "    totalTerms = totalLegitTerms + totalSpamTerms\n",
    "    \n",
    "    filepathList, actualClass = combineFiles(\"bare\")\n",
    "    for num in numFeatures:  \n",
    "        terms = pd.read_csv(\"MI/\"+corp.corpusName+\"/\"+str(num)+\"terms.csv\", index_col = 0)\n",
    "        print (\"Features: \", num) \n",
    "        \n",
    "        spamCount = terms['SpamCount'].tolist()\n",
    "        legitCount = terms['LegitCount'].tolist()\n",
    "        \n",
    "        for t in threshold:\n",
    "            print (\"Threshold: \", t)\n",
    "            predClass = classifyDocs(corp, terms, spamCount, legitCount, totalTerms,\n",
    "                                 filepathList, t, num)\n",
    "            writeResults(actualClass,predClass, corp, num, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now classify a corpus like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classify(bare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Classifying\", bare.corpusName)\n",
    "#load the vocabulary/word/term list for the entire corpus from file\n",
    "corpusTerms = pd.read_csv(\"Features/\"+bare.corpusName+\"/\"+bare.corpusName+\"termMI.csv\", index_col = 0)\n",
    "totalLegitTerms = corpusTerms['LegitCount'].sum(axis=0)\n",
    "totalSpamTerms = corpusTerms['SpamCount'].sum(axis=0)\n",
    "totalTerms = totalLegitTerms + totalSpamTerms\n",
    "\n",
    "filepathList, actualClass = combineFiles(\"bare\")\n",
    "num = 400 \n",
    "terms = pd.read_csv(\"MI/\"+bare.corpusName+\"/\"+str(num)+\"terms.csv\", index_col = 0)\n",
    "print (\"Features: \", num) \n",
    "\n",
    "spamCount = terms['SpamCount'].tolist()\n",
    "legitCount = terms['LegitCount'].tolist()\n",
    "\n",
    "t = 0.5\n",
    "print (\"Threshold: \", t)\n",
    "predClass = classifyDocs(bare, terms, spamCount, legitCount, totalTerms,\n",
    "                     filepathList, t, num)\n",
    "writeResults(actualClass,predClass, bare, num, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 48, 241)\n",
      "(279, 48, 231)\n",
      "(289, 48, 241)\n",
      "(289, 48, 241)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#subdirectory : 'Emails/bare\n",
    "def countDocuments(directory):\n",
    "    for path, subdirs, files in os.walk(directory):\n",
    "        for subdir in subdirs:\n",
    "            dir_path = os.path.join(path,subdir)\n",
    "            docCount = len([name for name in os.listdir(dir_path)])\n",
    "            spamCount = 0\n",
    "            legitCount = 0\n",
    "            for name in os.listdir(dir_path):\n",
    "                if name.startswith(\"spm\"):\n",
    "                    spamCount += 1\n",
    "                else:\n",
    "                    legitCount += 1\n",
    "    return docCount,spamCount,legitCount\n",
    "\n",
    "print(countDocuments('Emails/bare'))\n",
    "print(countDocuments('Emails/lemm'))\n",
    "print(countDocuments('Emails/lemm_stop'))\n",
    "print(countDocuments('Emails/stop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "After classifying the documents whether it is spam or legitimate, they have been done only for testing purposes, up until now. The last part of this tutorial covers about the Performance Evaluation. Check out and open <b><i>Performance Evaluation.ipynb</i></b> for the tutorial of this part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And then, We're Done! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
